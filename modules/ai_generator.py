import torch
from diffusers import KandinskyV22Pipeline, KandinskyV22PriorPipeline
from transformers import CLIPVisionModelWithProjection
from diffusers.models import UNet2DConditionModel
from config import DEVICE

class AIGenerator:
    def __init__(self):
        # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤ Device ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÑ‡∏ß‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
        self.device = DEVICE 
        print(f"Loading AI Models on {self.device}... This may take a while.")
        
        # ... (‡πÇ‡∏Ñ‡πâ‡∏î __init__ ‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì ‡∏Ñ‡∏á‡πÑ‡∏ß‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ...
        # ... (‡∏ä‡πà‡∏ß‡∏á‡πÇ‡∏´‡∏•‡∏î Model ‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏¥‡∏°) ...
        
        # ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ CPU ‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ .half() ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÅ‡∏ö‡∏ö‡∏õ‡∏Å‡∏ï‡∏¥ (float32)
        if self.device == 'cpu':
            # ... (‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏î‡∏¥‡∏°) ...
            self.image_encoder = CLIPVisionModelWithProjection.from_pretrained('kandinsky-community/kandinsky-2-2-prior', subfolder='image_encoder').to(self.device)
            self.unet = UNet2DConditionModel.from_pretrained('kandinsky-community/kandinsky-2-2-decoder', subfolder='unet').to(self.device)
            self.prior = KandinskyV22PriorPipeline.from_pretrained('kandinsky-community/kandinsky-2-2-prior', image_encoder=self.image_encoder, torch_dtype=torch.float32).to(self.device)
            self.decoder = KandinskyV22Pipeline.from_pretrained('kandinsky-community/kandinsky-2-2-decoder', unet=self.unet, torch_dtype=torch.float32).to(self.device)
        else:
            # ... (‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏î‡∏¥‡∏°) ...
            self.image_encoder = CLIPVisionModelWithProjection.from_pretrained('kandinsky-community/kandinsky-2-2-prior', subfolder='image_encoder').half().to(self.device)
            self.unet = UNet2DConditionModel.from_pretrained('kandinsky-community/kandinsky-2-2-decoder', subfolder='unet').half().to(self.device)
            self.prior = KandinskyV22PriorPipeline.from_pretrained('kandinsky-community/kandinsky-2-2-prior', image_encoder=self.image_encoder, torch_dtype=torch.float16).to(self.device)
            self.decoder = KandinskyV22Pipeline.from_pretrained('kandinsky-community/kandinsky-2-2-decoder', unet=self.unet, torch_dtype=torch.float16).to(self.device)

        print("AI Models Loaded Successfully.")

    # ------------------------------------------------------------------
    # [NEW] ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏•‡∏±‡∏ö CPU <-> GPU
    # ------------------------------------------------------------------
    def switch_device(self, target_device):
        if target_device == self.device:
            return True, f"Already on {target_device}"

        try:
            # ‡∏Å‡∏£‡∏ì‡∏µ‡∏à‡∏∞‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏õ GPU
            if target_device == 'cuda':
                if not torch.cuda.is_available():
                    return False, "No NVIDIA GPU found on this machine."
                
                print("üöÄ Switching AI to GPU (CUDA)...")
                # GPU ‡πÉ‡∏ä‡πâ float16 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î VRAM
                self.prior.to("cuda", torch.float16)
                self.decoder.to("cuda", torch.float16)
                self.device = 'cuda'
                return True, "Switched to GPU (High Performance)"

            # ‡∏Å‡∏£‡∏ì‡∏µ‡∏à‡∏∞‡∏¢‡πâ‡∏≤‡∏¢‡∏Å‡∏•‡∏±‡∏ö CPU
            elif target_device == 'cpu':
                print("üê¢ Switching AI to CPU...")
                # CPU ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡πÉ‡∏ä‡πâ float32
                self.prior.to("cpu", torch.float32)
                self.decoder.to("cpu", torch.float32)
                self.device = 'cpu'
                return True, "Switched to CPU (Low Performance)"
                
        except Exception as e:
            print(f"‚ùå Switch failed: {e}")
            return False, str(e)

    # ... (‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô generate_image ‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì) ...
    def generate_image(self, prompt, negative_prompt, seed, num_inference_steps=25):
        # ... (‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏î‡∏¥‡∏°) ...
        # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î generator ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ self.device ‡πÅ‡∏ó‡∏ô DEVICE ‡∏à‡∏≤‡∏Å config
        generator = torch.Generator(device=self.device).manual_seed(int(seed))
        
        # ... (‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ...
        img_emb = self.prior(prompt=prompt, num_inference_steps=num_inference_steps, generator=generator)
        negative_emb = self.prior(prompt=negative_prompt, num_inference_steps=num_inference_steps, num_images_per_prompt=1, generator=generator)
        images = self.decoder(image_embeds=img_emb.image_embeds, negative_image_embeds=negative_emb.image_embeds, num_inference_steps=num_inference_steps, height=512, width=512, generator=generator)
        
        return images.images[0]